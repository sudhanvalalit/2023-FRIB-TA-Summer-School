{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuclear Mass Net\n",
    "\n",
    "_Adapted from 2019 FRIB-TA summer school project_\n",
    "\n",
    "In this challenge you will use the powers of __neural networks__ to learn the global trends of nuclear masses. The setup of scalers and the network are similar to the challenge for the potential energy surfaces, but our input (at first) in only the simplest possible information -- nuclear charge and mass.\n",
    "\n",
    "In addition to plotting some predictions of the BE alone, see how well your network does on quantities like separation energies. How well do you predict the one and two neutron driplines?\n",
    "\n",
    "One very simple thing to try (beyond just changing the architecture) is to change the target quantity when performing regression to something like BE/A instead of BE. Another interesting thing to try is to investigate feeding in additional data beyond Z and A -- perhaps the network learns the difference from the liquid drop model better than the absolute BE? Let's find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import sklearn.linear_model as skl\n",
    "from pylab import plt, mpl\n",
    "# from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "\n",
    "def MakePlot(x,y, styles, labels, axlabels):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for i in range(len(x)):\n",
    "        plt.plot(x[i], y[i], styles[i], label = labels[i])\n",
    "        plt.xlabel(axlabels[0])\n",
    "        plt.ylabel(axlabels[1])\n",
    "    plt.legend(loc=0)\n",
    "    \n",
    "# R2 metric for tensorflow from https://jmlb.github.io/ml/2017/03/20/CoeffDetermination_CustomMetric4Keras/\n",
    "def R2(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "# input N,Z return model estimated binding energy\n",
    "def BE(N, Z):\n",
    "    # Hard code the data averages\n",
    "    nucleus=xscaler.transform(np.array([[Z,N]]))\n",
    "    [[BE]] = yscaler.inverse_transform(model.predict(nucleus,verbose=0))\n",
    "    return BE\n",
    "\n",
    "\n",
    "# Where to save the figures and data files\n",
    "PROJECT_ROOT_DIR = \"Results\"\n",
    "FIGURE_ID = \"Results/FigureFiles\"\n",
    "DATA_ID = \"DataFiles/\"\n",
    "\n",
    "if not os.path.exists(PROJECT_ROOT_DIR):\n",
    "    os.mkdir(PROJECT_ROOT_DIR)\n",
    "\n",
    "if not os.path.exists(FIGURE_ID):\n",
    "    os.makedirs(FIGURE_ID)\n",
    "\n",
    "if not os.path.exists(DATA_ID):\n",
    "    os.makedirs(DATA_ID)\n",
    "\n",
    "def image_path(fig_id):\n",
    "    return os.path.join(FIGURE_ID, fig_id)\n",
    "\n",
    "def data_path(dat_id):\n",
    "    return os.path.join(DATA_ID, dat_id)\n",
    "\n",
    "def save_fig(fig_id):\n",
    "    plt.savefig(image_path(fig_id) + \".png\", format='png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling\n",
    "\n",
    "First we'll read in the data and scale things to ensure they will be well behaved when the time comes to train our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open(data_path(\"MassEval2016.dat\"),'r')\n",
    "\n",
    "# Read the experimental data with Pandas\n",
    "Masses = pd.read_fwf(infile, usecols=(2,3,4,6,11),\n",
    "              names=('N', 'Z', 'A', 'Element', 'Ebinding'),\n",
    "              widths=(1,3,5,5,5,1,3,4,1,13,11,11,9,1,2,11,9,1,3,1,12,11,1),\n",
    "              header=39,\n",
    "              index_col=False)\n",
    "\n",
    "# Extrapolated values are indicated by '#' in place of the decimal place, so\n",
    "# the Ebinding column won't be numeric. Coerce to float and drop these entries.\n",
    "Masses['Ebinding'] = pd.to_numeric(Masses['Ebinding'], errors='coerce')\n",
    "Masses = Masses.dropna()\n",
    "# Convert from keV to MeV.\n",
    "Masses['Ebinding'] /= 1000\n",
    "\n",
    "# Group the DataFrame by nucleon number, A.\n",
    "#Masses = Masses.groupby('A')\n",
    "# Find the rows of the grouped DataFrame with the maximum binding energy.\n",
    "#Masses = Masses.apply(lambda t: t[t.Ebinding==t.Ebinding.max()])\n",
    "A = Masses['A']\n",
    "Z = Masses['Z']\n",
    "N = Masses['N']\n",
    "Element = Masses['Element']\n",
    "Energies = Masses['Ebinding']\n",
    "\n",
    "## All above comes from another notebook\n",
    "\n",
    "# Build input array\n",
    "xx = (Z.values[:],N.values[:])\n",
    "xx = np.asarray(xx)\n",
    "xx = xx.T\n",
    "aa = np.sum(xx,axis=1)\n",
    "yy = (-1.0*np.asarray(Energies)*aa).reshape(-1, 1)\n",
    "\n",
    "# Get a test set for later\n",
    "x_train, x_test, y_train, y_test = train_test_split(xx,yy,test_size=0.2,random_state=42)\n",
    "\n",
    "# Scale input\n",
    "\n",
    "xscaler = RobustScaler()\n",
    "xscaler.fit(x_train)\n",
    "\n",
    "xs_train = xscaler.transform(x_train)\n",
    "xs_test = xscaler.transform(x_test)\n",
    "xs_full = xscaler.transform(xx)\n",
    "\n",
    "yscaler = RobustScaler()\n",
    "yscaler.fit(y_train)\n",
    "\n",
    "ys_train = yscaler.transform(y_train)\n",
    "ys_test = yscaler.transform(y_test)\n",
    "ys_full = yscaler.transform(yy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Network\n",
    "\n",
    "I've got some skeleton code for building a network using Keras but I've left the middle layers of the cake for you to bake. The syntax is verrryyyy similar, but consider trying other Keras features to improve the efficiency of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nodes = 50\n",
    "activation=\"relu\"\n",
    "model=tf.keras.Sequential() #Define the model object\n",
    "model.add(tf.keras.layers.Dense(nodes,input_shape=(2,),activation=activation)) #Add the input layer\n",
    "\n",
    "model.add() #Add the hidden layer\n",
    "model.add() #Add the hidden layer\n",
    "model.add() #Add the hidden layer\n",
    "# do you need more hidden layers? Go for it if you want!\n",
    "\n",
    "model.add(tf.keras.layers.Dense(1)) #Add the output layer\n",
    "\n",
    "model.compile(tf.keras.optimizers.Adam(learning_rate=0.0001),loss='mean_squared_error',metrics=[R2]) #Adam optimizer and mean squared error loss\n",
    "results=model.fit(xs_train,ys_train,epochs=50, batch_size=8, validation_split=0.2,verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting and Performance\n",
    "\n",
    "The following cell has an abundance of metrics being plotted and printed to judge how well we're doing with our network.\n",
    "\n",
    "__Challenge:__ Binding energies are fine, but how do we do with separation energies? Plot those too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = results.history\n",
    "plt.plot(history[\"loss\"], label=\"training loss\")\n",
    "plt.plot(history[\"val_loss\"], label=\"validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "# test loss calculation\n",
    "\n",
    "[test_loss,test_R2]=model.evaluate(xs_test, ys_test, verbose=1)\n",
    "\n",
    "print('Test Loss: {:.04}'.format(test_loss))\n",
    "print('Test R2: {:.04}'.format(test_R2))\n",
    "\n",
    "testen_out=model.predict(xs_test)\n",
    "trainen_out=model.predict(xs_train)\n",
    "fullen_out=model.predict(xs_full)\n",
    "\n",
    "# Shift back for plotting\n",
    "\n",
    "x_train = xscaler.inverse_transform(xs_train)\n",
    "x_test = xscaler.inverse_transform(xs_test)\n",
    "x_full = xscaler.inverse_transform(xs_full)\n",
    "\n",
    "trainen_out = yscaler.inverse_transform(trainen_out).T.squeeze()\n",
    "testen_out = yscaler.inverse_transform(testen_out).T.squeeze()\n",
    "fullen_out = yscaler.inverse_transform(fullen_out).T.squeeze()\n",
    "\n",
    "a_test=np.sum(x_test,axis=1)\n",
    "a_train=np.sum(x_train,axis=1)\n",
    "a_full=np.sum(x_full,axis=1)\n",
    "\n",
    "en_test=np.asarray(y_test).squeeze()\n",
    "trainen_test=np.asarray(y_train).squeeze()\n",
    "fullen_test=np.asarray(yy).squeeze()\n",
    "\n",
    "diff = en_test-testen_out\n",
    "traindiff = trainen_test-trainen_out\n",
    "fulldiff = fullen_test-fullen_out\n",
    "\n",
    "diff = np.asarray(diff.T).squeeze()\n",
    "fulldiff = np.asarray(fulldiff.T).squeeze()\n",
    "traindiff = np.asarray(traindiff.T).squeeze()\n",
    "\n",
    "# diff = a_test*np.asarray(diff.T).squeeze()\n",
    "# fulldiff = a_full*np.asarray(fulldiff.T).squeeze()\n",
    "# traindiff = a_train*np.asarray(traindiff.T).squeeze()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(r'$A = N + Z$')\n",
    "ax.set_ylabel(r'$E_\\mathrm{bind}\\,/\\mathrm{MeV}$')\n",
    "ax.plot(Masses['A'], Masses['Ebinding'], 'o',\n",
    "            label='Ame2016', alpha=0.7,c='b')\n",
    "ax.plot(a_test, -testen_out/a_test,'o',c='m')\n",
    "ax.legend()\n",
    "save_fig(\"Masses2016\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(r'$N$')\n",
    "ax.set_ylabel(r'$\\Delta E_\\mathrm{bind}\\,/\\mathrm{MeV}$')\n",
    "#ax.plot(Masses['N'], Masses['Ebinding'], 'ro',\n",
    "#            label='Ame2016', alpha=0.7,c='b')\n",
    "\n",
    "\n",
    "plt.title(label=\"Test Set\")\n",
    "ax.plot(x_test[:,1], diff,'o',label='E Difference Test Set',c='r')\n",
    "#ax.plot(x_shift[:,1], y_test,'ro',c='r')\n",
    "\n",
    "ax.legend()\n",
    "save_fig(\"Difference\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(r'$N$')\n",
    "ax.set_ylabel(r'$\\Delta E_\\mathrm{bind}\\,/\\mathrm{MeV}$')\n",
    "#ax.plot(Masses['N'], Masses['Ebinding'], 'ro',\n",
    "#            label='Ame2016', alpha=0.7,c='b')\n",
    "\n",
    "ax.plot(x_train[:,1], traindiff,'o',label='E Difference Training Set',c='b')\n",
    "#ax.plot(x_shift[:,1], y_test,'ro',c='r')\n",
    "plt.title(label=\"Training Set\")\n",
    "#plt.ylim(-0.5,0.5)\n",
    "ax.legend()\n",
    "save_fig(\"Differencetrain\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(r'$N$')\n",
    "ax.set_ylabel(r'$\\Delta E_\\mathrm{bind}\\,/\\mathrm{MeV}$')\n",
    "#ax.plot(Masses['N'], Masses['Ebinding'], 'ro',\n",
    "#            label='Ame2016', alpha=0.7,c='b')\n",
    "\n",
    "ax.plot(x_full[:,1], fulldiff,'o',label='E Difference Full Set',c='m')\n",
    "#ax.plot(x_shift[:,1], y_test,'ro',c='r')\n",
    "plt.title(label=\"Full Set\")\n",
    "#plt.ylim(-0.5,0.5)\n",
    "ax.legend()\n",
    "save_fig(\"Differencefull\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(r'$N$')\n",
    "ax.set_ylabel(r'$\\Delta E_\\mathrm{bind}\\,/\\mathrm{MeV}$')\n",
    "#ax.plot(Masses['N'], Masses['Ebinding'], 'ro',\n",
    "#            label='Ame2016', alpha=0.7,c='b')\n",
    "\n",
    "ax.plot(x_train[:,1], traindiff,'o',label='E Difference Training Set',c='b')\n",
    "ax.plot(x_test[:,1], diff,'o',label='E Difference Test Set',c='r')\n",
    "#ax.plot(x_shift[:,1], y_test,'ro',c='r')\n",
    "plt.title(label=\"Training Set\")\n",
    "#plt.ylim(-0.5,0.5)\n",
    "ax.legend()\n",
    "save_fig(\"Differenceboth\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
